{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version:  2.0.0\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, GRU, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print('tensorflow version: ',tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "LSTM_NODES =256\n",
    "NUM_SENTENCES = 2500\n",
    "MAX_SENTENCE_LENGTH = 50\n",
    "MAX_NUM_WORDS = 2500\n",
    "EMBEDDING_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wow!\\tवाह!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #6179147 (fastrizwaan)\\n', 'Help!\\tबचाओ!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #459377 (minshirui)\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(r'/Users/user/Desktop/python_stuff/NLP/hin-eng/hin.txt', encoding=\"utf-8\") as file:\n",
    "    head = [next(file) for x in range(2)]\n",
    "print(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples input: 2500\n",
      "num samples output: 2500\n",
      "num samples output input: 2500\n"
     ]
    }
   ],
   "source": [
    "# We limit the sentences to 2500.\n",
    "# File has English sentence its corrosponding Hindi sentence and its attribute.\n",
    "# We need to split them by '\\t' and create a list of English sentences, its corrosponding Hindi sentences with\n",
    "# end of sentence <eos> postfix and a third list of same Hindi sentences with start of sentence <sos> prefix\n",
    "\n",
    "input_sentences = []\n",
    "output_sentences = []\n",
    "output_sentences_inputs = []\n",
    "\n",
    "count = 0\n",
    "for line in open(r'/Users/user/Desktop/python_stuff/NLP/hin-eng/hin.txt', encoding=\"utf-8\"):\n",
    "    count += 1\n",
    "\n",
    "    if count > NUM_SENTENCES:\n",
    "        break\n",
    "\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "\n",
    "    input_sentence, output, attribute = line.rstrip().split('\\t')\n",
    "\n",
    "    output_sentence = output + ' <eos>'\n",
    "    output_sentence_input = '<sos> ' + output\n",
    "\n",
    "    input_sentences.append(input_sentence)\n",
    "    output_sentences.append(output_sentence)\n",
    "    output_sentences_inputs.append(output_sentence_input)\n",
    "\n",
    "print(\"num samples input:\", len(input_sentences))\n",
    "print(\"num samples output:\", len(output_sentences))\n",
    "print(\"num samples output input:\", len(output_sentences_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence:  He has long legs.\n",
      "Output sentence:  उसके पैर लम्बे हैं। <eos>\n",
      "Output sentence as input:  <sos> उसके पैर लम्बे हैं।\n"
     ]
    }
   ],
   "source": [
    "print('Input sentence: ',input_sentences[250])\n",
    "print('Output sentence: ',output_sentences[250])\n",
    "print('Output sentence as input: ',output_sentences_inputs[250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words:  2096\n",
      "Longest sentence has 12 words\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input sentences(English Language)\n",
    "\n",
    "input_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "input_tokenizer.fit_on_texts(input_sentences)\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
    "\n",
    "max_input_len = max(len(x) for x in input_integer_seq)\n",
    "print('Total unique words: ',len(input_word_index))\n",
    "\n",
    "input_word_index = input_tokenizer.word_index\n",
    "print('Longest sentence has {} words'.format(max_input_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words are:  2755\n",
      "Length of longest sentence in the output: 17\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the output sentences(Hindi Language)\n",
    "\n",
    "output_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
    "output_tokenizer.fit_on_texts(output_sentences + output_sentences_inputs)\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
    "\n",
    "output_word_index = output_tokenizer.word_index\n",
    "print('Total unique words are: ', len(output_word_index))\n",
    "\n",
    "max_out_len = max(len(x) for x in output_integer_seq)\n",
    "print(\"Length of longest sentence in the output: %g\" % max_out_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We need to pad our inputs and outputs because each inputs and outputs are of different length \n",
    "<p>LSTM model expects all the inputs to be of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded input sequence shape:  (2500, 12)\n",
      "padded input sequence example 250:  [  0   0   0   0   0   0   0   0   7  37  77 614]\n"
     ]
    }
   ],
   "source": [
    "# Input padding\n",
    "\n",
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "print('padded input sequence shape: ',encoder_input_sequences.shape)\n",
    "print('padded input sequence example 250: ', encoder_input_sequences[250])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer associated with \"He\" is:  7\n",
      "Integer associated with \"has\" is:  37\n",
      "Integer associated with \"long\" is:  77\n",
      "Integer associated with \"legs\" is:  614\n"
     ]
    }
   ],
   "source": [
    "print('Integer associated with \"He\" is: ',input_word_index['he'])\n",
    "print('Integer associated with \"has\" is: ',input_word_index['has'])\n",
    "print('Integer associated with \"long\" is: ',input_word_index['long'])\n",
    "print('Integer associated with \"legs\" is: ',input_word_index['legs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded output sequence shape:  (2500, 17)\n",
      "padded output sequence example 250:  [  2  49 537 547  12   0   0   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "# Output padding\n",
    "\n",
    "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print('padded output sequence shape: ', decoder_input_sequences.shape)\n",
    "print('padded output sequence example 250: ', decoder_input_sequences[250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer associated with \"<sos>\" is:  2\n",
      "Integer associated with \"उसके\" is:  49\n",
      "Integer associated with \"पैर\" is:  537\n",
      "Integer associated with \"लम्बे\" is:  547\n",
      "Integer associated with \"हैं।\" is:  12\n"
     ]
    }
   ],
   "source": [
    "print('Integer associated with \"<sos>\" is: ',output_word_index['<sos>'])\n",
    "print('Integer associated with \"उसके\" is: ',output_word_index['उसके'])\n",
    "print('Integer associated with \"पैर\" is: ',output_word_index['पैर'])\n",
    "print('Integer associated with \"लम्बे\" is: ',output_word_index['लम्बे'])\n",
    "print('Integer associated with \"हैं।\" is: ',output_word_index['हैं।'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 17)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 49, 537, 547,  12,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(decoder_output_sequences.shape)\n",
    "decoder_output_sequences[250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In the encoder, zeros were padded at the beginning. \n",
    "The reason behind this is that encoder output is based on the words occurring at the end of the sentence, \n",
    "therefore the original words were kept at the end of the sentence and zeros were padded at the beginning. \n",
    "In the case of the decoder, the post-padding is applied,\n",
    "which means that zeros are appended at the end of the sentence. \n",
    "We do this because in the decoder the processing starts from the beginning of a sentence, \n",
    "hence post-padding is performed in the decoder.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>For the English sentences, i.e. the inputs, we will use the GloVe word embeddings. For the translated Hindi sentences in the output, we will use custom word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reate a dictionary where words are the keys and the corresponding vectors are values\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "glove_file = open(r\"/Users/user/Desktop/python_stuff/NLP/glove.6B/glove.6B.100d.txt\", encoding='utf8')\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary[word] = vector_dimensions\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = min(MAX_NUM_WORDS, len(input_word_index)+1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_SIZE))\n",
    "for word, index in input_word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1225   , -0.058833 ,  0.23658  , -0.28877  , -0.028181 ,\n",
       "        0.31524  ,  0.070229 ,  0.16447  , -0.027623 ,  0.25214  ,\n",
       "        0.21174  , -0.059674 ,  0.36133  ,  0.13607  ,  0.18755  ,\n",
       "       -0.1487   ,  0.31315  ,  0.13368  , -0.59703  , -0.030161 ,\n",
       "        0.080656 ,  0.26162  , -0.055924 , -0.35351  ,  0.34722  ,\n",
       "       -0.0055801, -0.57935  , -0.88007  ,  0.42931  , -0.15695  ,\n",
       "       -0.51256  ,  1.2684   , -0.25228  ,  0.35265  , -0.46419  ,\n",
       "        0.55648  , -0.57556  ,  0.32574  , -0.21893  , -0.13178  ,\n",
       "       -1.1027   , -0.039591 ,  0.89643  , -0.9845   , -0.47393  ,\n",
       "       -0.12855  ,  0.63506  , -0.94888  ,  0.40088  , -0.77542  ,\n",
       "       -0.35153  , -0.27788  ,  0.68747  ,  1.458    , -0.38474  ,\n",
       "       -2.8937   , -0.29523  , -0.38836  ,  0.94881  ,  1.3891   ,\n",
       "        0.054591 ,  0.70486  , -0.65699  ,  0.075648 ,  0.7655   ,\n",
       "       -0.63365  ,  0.86556  ,  0.42441  ,  0.14796  ,  0.4156   ,\n",
       "        0.29354  , -0.51295  ,  0.19635  , -0.45568  ,  0.0080246,\n",
       "        0.14528  , -0.15395  ,  0.11406  , -1.2167   , -0.1111   ,\n",
       "        0.8264   ,  0.21738  , -0.63776  , -0.074874 , -1.713    ,\n",
       "       -0.8827   , -0.0073058, -0.37623  , -0.50209  , -0.58844  ,\n",
       "       -0.24943  , -1.0425   ,  0.27678  ,  0.64142  , -0.64605  ,\n",
       "        0.43559  , -0.37276  , -0.0032068,  0.18744  ,  0.30702  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dictionary['he']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1225    , -0.058833  ,  0.23658   , -0.28876999, -0.028181  ,\n",
       "        0.31524   ,  0.070229  ,  0.16447   , -0.027623  ,  0.25213999,\n",
       "        0.21174   , -0.059674  ,  0.36133   ,  0.13607   ,  0.18754999,\n",
       "       -0.1487    ,  0.31314999,  0.13368   , -0.59702998, -0.030161  ,\n",
       "        0.080656  ,  0.26161999, -0.055924  , -0.35350999,  0.34722   ,\n",
       "       -0.0055801 , -0.57934999, -0.88006997,  0.42930999, -0.15695   ,\n",
       "       -0.51256001,  1.26839995, -0.25228   ,  0.35264999, -0.46419001,\n",
       "        0.55647999, -0.57555997,  0.32574001, -0.21893001, -0.13178   ,\n",
       "       -1.1027    , -0.039591  ,  0.89643002, -0.98449999, -0.47393   ,\n",
       "       -0.12854999,  0.63506001, -0.94888002,  0.40088001, -0.77542001,\n",
       "       -0.35152999, -0.27788001,  0.68747002,  1.45799994, -0.38474   ,\n",
       "       -2.89369988, -0.29523   , -0.38835999,  0.94880998,  1.38909996,\n",
       "        0.054591  ,  0.70485997, -0.65698999,  0.075648  ,  0.76550001,\n",
       "       -0.63365   ,  0.86556   ,  0.42440999,  0.14796001,  0.4156    ,\n",
       "        0.29354   , -0.51295   ,  0.19634999, -0.45568001,  0.0080246 ,\n",
       "        0.14528   , -0.15395001,  0.11406   , -1.21669996, -0.1111    ,\n",
       "        0.82639998,  0.21738   , -0.63775998, -0.074874  , -1.71300006,\n",
       "       -0.88270003, -0.0073058 , -0.37623   , -0.50208998, -0.58844   ,\n",
       "       -0.24943   , -1.04250002,  0.27678001,  0.64142001, -0.64604998,\n",
       "        0.43559   , -0.37276   , -0.0032068 ,  0.18743999,  0.30702001])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(num_words, EMBEDDING_SIZE, weights=[embedding_matrix], input_length=max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_targets_one_hot = np.zeros((len(input_sentences),\n",
    "                                    max_out_len,\n",
    "                                    num_words_output),\n",
    "                                    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 17, 2756)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_targets_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(decoder_output_sequences):\n",
    "    for t, word in enumerate(d):\n",
    "        decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
